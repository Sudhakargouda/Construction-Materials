# robots.txt for an construction materials website

# Allow all web crawlers access to the website
User-agent: *
Disallow:

# Disallow web crawlers from accessing certain sensitive directories
Disallow: /admin/
Disallow: /user/
Disallow: /cart/
Disallow: /checkout/
Disallow: /order-history/
Disallow: /login/
Disallow: /register/

# Disallow access to API endpoints
Disallow: /api/

# Disallow access to temporary or private files
Disallow: /temp/
Disallow: /private/

# Allow access to the product pages
Allow: /products/

# Allow access to the categories pages
Allow: /categories/


